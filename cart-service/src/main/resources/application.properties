spring.kafka.producer.value-serializer=io.confluent.kafka.serializers.json.KafkaJsonSchemaSerializer
spring.kafka.producer.properties.schema.registry.url=http://localhost:8081
spring.kafka.producer.properties.auto.register.schemas=true
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer

spring.kafka.bootstrap-servers=localhost:9092

spring.datasource.url=jdbc:mysql://localhost:3306/cart-service?createDatabaseIfNotExist=true
spring.datasource.username=root
spring.datasource.password=
spring.jpa.hibernate.ddl-auto=update
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver

spring.data.redis.host=localhost
spring.data.redis.port=6379

spring.application.name=cart-service
server.port=8084

eureka.client.service-url.defaultZone=http://eureka:password@localhost:8761/eureka/
spring.security.oauth2.resourceserver.jwt.issuer-uri=http://keycloak:8085/realms/spring-boot-microservices-realm

# ==========================================================
# CÀI ĐẶT TỐI ƯU HÓA CHO CART-SERVICE
# ==========================================================

# 1. TĂNG POOL CSDL (HIKARI) (Fix Bottleneck 1)
spring.datasource.hikari.maximum-pool-size=200
spring.datasource.hikari.minimum-idle=20
spring.datasource.hikari.connection-timeout=30000

# 2. TĂNG POOL REDIS (LETTUCE) (Fix Bottleneck 2)
spring.data.redis.lettuce.pool.min-idle=10

# 3. TĂNG "KIÊN NHẪN" CHO KAFKA PRODUCER (Fix Bottleneck 3)
# Đổi acks từ "all" sang "1" khi load test để Producer không bị treo chờ Broker confirm.
spring.kafka.producer.acks=all
#spring.kafka.producer.acks=1
spring.kafka.producer.properties.enable.idempotence=true
#spring.kafka.producer.properties.enable.idempotence=false
#spring.kafka.producer.properties.retries=10
spring.kafka.producer.properties.retries=3
spring.kafka.producer.properties.max.in.flight.requests.per.connection=5
#spring.kafka.producer.properties.max.block.ms=30000
spring.kafka.producer.properties.max.block.ms=5000

# 1. Cấu hình Deserializer
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=io.confluent.kafka.serializers.json.KafkaJsonSchemaDeserializer

# 2. Cấu hình Schema Registry (lấy từ config producer đã có)
# Đảm bảo consumer biết tìm Schema Registry ở đâu
spring.kafka.properties.schema.registry.url=${spring.kafka.producer.properties.schema.registry.url}

# 3. Chỉ rõ class mục tiêu cho JSON Schema Deserializer
# (Thay thế 'com.myexampleproject.common.event' bằng package đúng của bạn nếu khác)
spring.kafka.consumer.properties.json.value.type=com.myexampleproject.common.event.CartCheckoutEvent

# 4. Cấu hình an toàn
spring.kafka.consumer.properties.json.ignore.unknown=true

spring.kafka.consumer.group-id=cart-group

# Cho phép Prometheus đọc được metrics
management.endpoints.web.exposure.include=prometheus,health
management.endpoint.health.show-details=always

spring.kafka.listener.ack-mode=batch

#logging.level.root=WARN
#logging.level.root=ERROR

# ==========================================================
# CẤU HÌNH TOMCAT TUNING (SỬA LẠI ĐỂ KHỚP VỚI DB)
# ==========================================================

# 1. Số luồng xử lý tối đa -> GIẢM XUỐNG BẰNG DB POOL
# Lý do: Nếu để 600 luồng mà chỉ có 200 kết nối DB, thì 400 luồng kia sẽ bị treo
# gây tắc nghẽn RAM và Network. Hãy để Tomcat xếp hàng ở ngoài (accept-count) thay vì xếp hàng chờ DB.

# 2. Số luồng tối thiểu
server.tomcat.threads.min-spare=50

# 3. Tổng số kết nối TCP tối đa (Giữ nguyên mức cao để nhận kết nối từ Gateway)
server.tomcat.max-connections=8192

# 4. Hàng đợi chờ (Backlog) - Giữ nguyên mức cao
# Khi 250 luồng đang bận, các request còn lại sẽ nằm chờ ở đây (cấp độ mạng)
# Gateway sẽ không bị "Connection refused".
server.tomcat.accept-count=3000

# 5. Connection Timeout
# Thêm dòng này để Tomcat tự đóng kết nối treo quá lâu (tránh lỗi ClosedChannel do phía Gateway ngắt trước)
server.tomcat.connection-timeout=20000
server.tomcat.threads.max=400

# Cấu hình Pool cho Redis (Lettuce)
spring.data.redis.lettuce.pool.max-active=500
spring.data.redis.lettuce.pool.max-idle=50
spring.data.redis.lettuce.pool.max-wait=10000ms

#spring.kafka.streams.properties.state.dir=${java.io.tmpdir}/kafka-streams/${spring.application.name}/${random.uuid}
logging.level.root=ERROR